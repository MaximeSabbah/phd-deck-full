<section data-part-group="part-i" data-part-title="PART I"
         style="--part-accent: var(--c-laas-red);">
<section data-auto-animate>
    <h2 style="background-color:var(--c-laas-red); margin:0px;">
        [PART_NAME_I]
    </h2>
    <h3 style="background-color:#e94b58d2; margin-top:0px;">
        Focus
    </h3>
    <div>
        How to estimate human kinematics
        <b>in real-time and ecologically</b>
        while achieving
        <b>laboratory-grade accuracy</b>?
    </div>
    <!-- using low-cost and user-comfortable sensors -->
</section>
</section>

<section data-part-group="part-i" data-part-title="[PART_NAME_I]"
         style="--part-accent: var(--c-laas-red);">
  <section data-auto-animate data-transition="fade-out">
      <h2 style="background-color:var(--c-laas-red); margin:0px;">
          [PART_NAME_I]
      </h2>
      <h3 style="background-color:#e94b58d2; margin-top:0px;">
          State-of-the-art
      </h3>
      <div style="width: 50%; font-size: 0.8em;" class="col">
        <span style="font-weight: bold;" data-id="feature_1">Optical Mocap</span>
          <video data-autoplay loop muted playsinline style="width: 100%;">
                  <source data-src="./videos/Part-I/optitrack.mp4" type="video/mp4">
          </video>
          <figcaption class="citation-small" style="text-align: center;"> OptiTrack </figcaption>

        <div class="fragment" data-fragment-index="1" style="text-align:left; font-size:0.6em;">
          <ul class="pc-list">
              <li class="pro">Reference system in terms of accuracy.</li>
          </ul>
        </div>
        <div class="fragment" data-fragment-index="2" style="text-align:left; font-size:0.6em;">
          <ul class="pc-list">
              <li class="con">Cumbersome and expensive.</li>
          </ul>
        </div>
      </div>
      <div class="fragment" data-fragment-index="3">
        <div style="width: 50%; font-size: 0.8em;" class="col">
            <span style="font-weight: bold;" data-id="feature_2">OpenPose/Kinect</span>
            <ul>
                <video data-autoplay loop muted playsinline style="width: 100%;">
                    <source data-src="./videos/Part-I/openpose.mp4" type="video/mp4">
                </video>
                <div class="citation-small" style="text-align: center;"> Z. Cao et al., <em>Openpose: Realtime multi-person 2d pose estimation using part affinity fields</em>, IEEE PAMI, 2019</div>
            </ul>
            <div class="fragment" style="text-align:left; font-size:0.6em;">
              <ul class="pc-list">
                  <li class="pro">Not invasive, requiring a minimal number of cameras.</li>
              </ul>
            </div>
            <div class="fragment" style="text-align:left; font-size:0.6em;">
              <ul class="pc-list">
                  <li class="con">Not robust enough.</li>
              </ul>
            </div>
            <div class="fragment" style="text-align:left; font-size:0.6em;">
              <ul class="pc-list">
                  <li class="con">Limited accuracy</li>
              </ul>
              <div class="citation-small" style="font-size:.4em; text-align:center; margin-top:0.3rem;">
                J. Colombel et al. <em>Markerless 3D Human Pose Tracking in the Wild with fusion of Multiple Depth Cameras.</em>, Springer, 2020
              </div>
            </div>
        </div>
      </div>
</section>
</section>

<section data-part-group="part-i" data-part-title="[PART_NAME_I]"
         style="--part-accent: var(--c-laas-red);">
  <section data-auto-animate data-transition="fade-out">
      <h2 style="background-color:var(--c-laas-red); margin:0px;">
          [PART_NAME_I]
      </h2>
      <h3 style="background-color:#e94b58d2; margin-top:0px;">
          State-of-the-art
      </h3>
      <div style="width: 50%; font-size: 0.8em;" class="col">
          <span style="font-weight: bold;" data-id="feature_1">Skeleton tracking:</span>
          <ul>
              <video data-autoplay loop muted playsinline style="width: 100%;">
                  <source data-src="./videos/Part-I/rtmpose.mp4" type="video/mp4">
              </video>
              <div class="citation-small" style="text-align: center;">T. Jiang et al., <em>RTMPose: Real-Time Multi-Person Pose Estimation based on MMPose</em>, CVPR, 2023</div>
          </ul>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="pro">Lightweight and real-time.</li>
            </ul>
          </div>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="con">Outputs a minimal set of keypoints.</li>
            </ul>
          </div>
      </div>
      <div style="width: 50%; font-size: 0.8em;" class="col">
          <span style="font-weight: bold;" data-id="feature_2">Human mesh recovery:</span>
          <ul>
              <video data-autoplay loop muted playsinline style="width: 100%;">
                  <source data-src="./videos/Part-I/nlf.mp4" type="video/mp4">
              </video>
              <div class="citation-small" style="text-align: center;"> I. Sarandi and G. Pons-Moll, <em>Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation</em>, CVPR, 2024</div>
          </ul>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="pro">Volumetric representation of the whole body.</li>
            </ul>
          </div>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="con">Computationally expensive.</li>
            </ul>
          </div>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="con">Biomechanical fidelity?</li>
            </ul>
          </div>
          <div class="fragment" style="text-align:left; font-size:0.6em;">
            <ul class="pc-list">
                <li class="con">Accuracy to be validated.</li>
            </ul>
          </div>
      </div>
  </section>

  <section data-auto-animate data-transition="fade">
    <h2 style="background-color:var(--c-laas-red); margin:0;">Estimating human state in real time</h2>
    <h3 style="background-color:#e94b58d2; margin-top:0;">State-of-the-art</h3>

    <!-- Compact frame (smaller typography so everything fits) -->
    <div style="max-width:1250px; margin:.6rem auto 0; padding:.7rem; border:2px solid #0d2a4a; border-radius:14px; font-size:.52em; line-height:1.22;">
      <!-- Badge with logo on brand pill -->
      <div style="display:inline-flex; align-items:center; gap:.45rem; padding:.18rem .6rem; border:1px solid rgba(13,42,74,.9); border-radius:999px; background:#0d2a4a; transform:translateY(-1.95rem);">
        <img src="./assets/logos/opencap.png" alt="OpenCap" style="height:25px; width:auto; display:block;">
      </div>

      <div class="pipeline-pc">
        <!-- PROS (left) -->
        <ul class="pc-list">
          <li class="pro fragment" data-fragment-index="4">
            Accuracy of 5deg validated for common tasks.
          </li>
        </ul>

        <!-- CONS (right) -->
        <ul class="pc-list">
          <li class="con fragment" data-fragment-index="5">Not real-time.</li>
          <li class="con fragment" data-fragment-index="6">Privacy concerns.</li>
        </ul>
      </div>

      <!-- Pipeline cards -->
      <div class="pipeline-cards">

      <!-- CARD 1 -->
      <div class="pipeline-card fragment" data-fragment-index="0" style="flex:0 0 230px;">
        <h4>Multi-view 2D keypoints</h4>
        <div class="sub">HPE per camera (â‰¥2 views)</div>
        <div style="display:flex; flex-direction:column; gap:.3rem;">
          <video data-autoplay loop muted playsinline
                style="width:100%; border-radius:8px; border:1px solid rgba(0,0,0,.12);">
            <source data-src="./videos/Part-I/rtmpose.mp4" type="video/mp4">
          </video>
          <video data-autoplay loop muted playsinline
                style="width:100%; border-radius:8px; border:1px solid rgba(0,0,0,.12);">
            <source data-src="./videos/Part-I/rtmpose.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <!-- Arrow -->
      <svg class="pipeline-arrow fragment" data-fragment-index="1"
          viewBox="0 0 34 12" width="34" height="12">
        <defs><marker id="arrA" markerWidth="8" markerHeight="8" refX="7" refY="4" orient="auto">
          <polygon points="0,0 8,4 0,8" fill="#0d2a4a"/></marker></defs>
        <line x1="1" y1="6" x2="33" y2="6" stroke="#0d2a4a" stroke-width="3" marker-end="url(#arrA)"/>
      </svg>

      <!-- CARD 2 -->
      <div class="pipeline-card fragment" data-fragment-index="1" style="flex:0 0 210px;">
        <h4>Triangulation</h4>
        <!-- your original SVG unchanged -->
        <svg viewBox="0 0 220 90" width="100%" height="auto" style="display:block;">
          <defs>
            <marker id="arrTri" markerWidth="8" markerHeight="8" refX="7" refY="4" orient="auto">
              <polygon points="0,0 8,4 0,8" fill="#0d2a4a"/>
            </marker>
            <radialGradient id="dotR" cx="50%" cy="50%" r="50%">
              <stop offset="0%" stop-color="#ff6b6b"/><stop offset="100%" stop-color="#c43d3d"/>
            </radialGradient>
          </defs>
          <rect x="12" y="30" width="28" height="18" rx="3" fill="#e2ecf7" stroke="#0d2a4a"/>
          <rect x="180" y="12" width="28" height="18" rx="3" fill="#e2ecf7" stroke="#0d2a4a"/>
          <line x1="40" y1="39" x2="110" y2="58" stroke="#0d2a4a" stroke-width="2" marker-end="url(#arrTri)"/>
          <line x1="180" y1="21" x2="110" y2="58" stroke="#0d2a4a" stroke-width="2" marker-end="url(#arrTri)"/>
          <circle cx="110" cy="58" r="4" fill="url(#dotR)"/>
        </svg>
      </div>

      <!-- Arrow -->
      <svg class="pipeline-arrow fragment" data-fragment-index="2"
          viewBox="0 0 34 12" width="34" height="12">
        <use href="#arrA"></use>
        <line x1="1" y1="6" x2="33" y2="6" stroke="#0d2a4a" stroke-width="3" marker-end="url(#arrA)"/>
      </svg>

      <!-- CARD 3 -->
      <div class="pipeline-card fragment" data-fragment-index="2" style="flex:0 0 210px;">
        <h4>Marker augmentation</h4>
        <img src="./assets/part-I/augmenter_output.png" alt="Augmented Markers"
            style="width:100%; max-height:450px; object-fit:contain; display:block; margin-top:.25rem;">
      </div>

      <!-- Arrow -->
      <svg class="pipeline-arrow fragment" data-fragment-index="3"
          viewBox="0 0 34 12" width="34" height="12">
        <use href="#arrA"></use>
        <line x1="1" y1="6" x2="33" y2="6" stroke="#0d2a4a" stroke-width="3" marker-end="url(#arrA)"/>
      </svg>

      <!-- CARD 4 -->
      <div class="pipeline-card fragment" data-fragment-index="3" style="flex:0 0 230px;">
        <h4>Inverse kinematics &amp; dynamics</h4>
         <div class="sub">OpenSim</div>
        <img src="./assets/part-I/opensim.png" alt="OpenSim"
            style="width:100%; max-height:250px; object-fit:contain; display:block; margin-top:.25rem;">
      </div>
    </div>
  </div>


      <!-- 2) FINAL OVERLAY: big red cross + label (appears last) -->
      <!-- FINAL OVERLAY: big red cross + lowercase label below -->
      <!-- <div class="fragment" data-fragment-index="4"
          style="position:absolute; inset:.4rem; display:flex; align-items:center; justify-content:center; pointer-events:none;">
        <svg viewBox="0 0 1200 520" width="100%" height="100%" style="opacity:.95;">
          <defs>
            <filter id="xShadow" x="-20%" y="-20%" width="140%" height="140%">
              <feDropShadow dx="0" dy="2" stdDeviation="6" flood-color="#7f1d1d" flood-opacity=".35"/>
            </filter>
            <style>
              <![CDATA[
              @keyframes drawX { to { stroke-dashoffset: 0; } }
              .xline{
                stroke:#e11d48; stroke-width:42; stroke-linecap:round;
                filter:url(#xShadow); fill:none; stroke-dasharray:1600; stroke-dashoffset:1600;
                animation: drawX .9s ease-out forwards;
              }
              .xline.second{ animation-delay:.18s; }
              .xtext{
                font: 800 110px/1.05 Inter, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
                fill:#e11d48; letter-spacing:1px; filter:url(#xShadow);
              }
              @media (max-width: 1100px){
                .xtext{ font-size: 92px; }
              }
              ]]>
            </style>
          </defs> -->

          <!-- big X -->
          <!-- <line x1="80"  y1="40"  x2="1120" y2="420" class="xline"/>
          <line x1="1120" y1="40"  x2="80"   y2="420" class="xline second"/> -->

          <!-- lowercase label *below* the cross -->
          <!-- <text x="50%" y="490" text-anchor="middle" class="xtext">not real-time</text>
        </svg>
      </div> -->
    <!-- </div> -->

    <!-- Single citation (smaller) -->
    <div class="citation-small" style="font-size:.4em; text-align:center;">
      S. Uhlrich et al., <em>OpenCap: Human movement dynamics from smartphone videos</em>, PLOS Computational Biology, 2023
    </div>
  </section>
</section>